import React, { useEffect, useRef, useState, useCallback } from 'react';
import './GroupVideoCallInterface.css';
import { GroupWebRTCService } from '../../services/webrtc/GroupWebRTCService';
import { leaveGroupCall, endGroupCall } from '../../api/videocall/groupVideoCallApi';
import { Client } from '@stomp/stompjs';

interface ParticipantInfo {
  userId: string;
  userName: string;
  userAvatar: string;
}

interface GroupVideoCallInterfaceProps {
  callId: string;
  groupId: string;
  groupName: string;
  initiatorId: string;
  currentUserId: string;
  participants: ParticipantInfo[];
  onCallEnded: () => void;
  stompClient: Client | null;
}

interface RemoteStream {
  userId: string;
  userName: string;
  userAvatar: string;
  stream: MediaStream;
}

const GroupVideoCallInterface: React.FC<GroupVideoCallInterfaceProps> = ({
  callId,
  groupId,
  groupName,
  initiatorId,
  currentUserId,
  participants,
  onCallEnded,
  stompClient,
}) => {
  const [webrtcService] = useState(() => new GroupWebRTCService(stompClient));
  const [remoteStreams, setRemoteStreams] = useState<RemoteStream[]>([]);
  const [isAudioEnabled, setIsAudioEnabled] = useState(true);
  const [isVideoEnabled, setIsVideoEnabled] = useState(true);
  const [connectionStates, setConnectionStates] = useState<Map<string, string>>(new Map());
  const [activeParticipants, setActiveParticipants] = useState<ParticipantInfo[]>(participants);
  
  const localVideoRef = useRef<HTMLVideoElement>(null);
  const localStreamRef = useRef<MediaStream | null>(null);

  // Debug log
  console.log('ğŸ¬ GroupVideoCallInterface mounted with:');
  console.log('  Current User ID:', currentUserId);
  console.log('  Participants:', participants);
  console.log('  Call ID:', callId);

  useEffect(() => {
    const initializeCall = async () => {
      try {
        // Get real camera/microphone
        const stream = await navigator.mediaDevices.getUserMedia({
          video: {
            width: { ideal: 1280 },
            height: { ideal: 720 },
            facingMode: 'user'
          },
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
          }
        });

        // Save stream to ref for cleanup
        localStreamRef.current = stream;

        // Display local video
        if (localVideoRef.current) {
          localVideoRef.current.srcObject = stream;
        }

        // Initialize WebRTC service
        webrtcService.initialize(stream, callId, currentUserId);

        // Create offers for existing participants
        console.log('ğŸ‘¥ Creating offers for existing participants...');
        console.log('Total participants:', participants.length);
        console.log('Current user:', currentUserId);
        
        let offersCreated = 0;
        participants.forEach((participant) => {
          console.log('Checking participant:', participant.userId, participant.userName);
          if (participant.userId !== currentUserId) {
            console.log('âœ… Creating offer to:', participant.userName);
            webrtcService.createOffer(participant.userId, handleRemoteStream);
            offersCreated++;
          } else {
            console.log('â­ï¸ Skipping self:', participant.userName);
          }
        });
        
        console.log(`ğŸ“Š Created ${offersCreated} offers for existing participants`);

      } catch (error: any) {
        console.error('Error initializing call:', error);
        let errorMessage = 'KhÃ´ng thá»ƒ khá»Ÿi táº¡o cuá»™c gá»i. ';
        
        if (error.name === 'NotAllowedError') {
          errorMessage += 'Báº¡n Ä‘Ã£ tá»« chá»‘i quyá»n truy cáº­p camera/microphone. Vui lÃ²ng cho phÃ©p quyá»n truy cáº­p vÃ  thá»­ láº¡i.';
        } else if (error.name === 'NotFoundError') {
          errorMessage += 'KhÃ´ng tÃ¬m tháº¥y camera hoáº·c microphone. Vui lÃ²ng kiá»ƒm tra thiáº¿t bá»‹ cá»§a báº¡n.';
        } else if (error.name === 'NotReadableError') {
          errorMessage += 'Camera/microphone Ä‘ang Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi á»©ng dá»¥ng khÃ¡c. Vui lÃ²ng Ä‘Ã³ng cÃ¡c á»©ng dá»¥ng khÃ¡c vÃ  thá»­ láº¡i.';
        } else if (error.name === 'OverconstrainedError') {
          errorMessage += 'KhÃ´ng thá»ƒ Ä‘Ã¡p á»©ng yÃªu cáº§u camera/microphone. Vui lÃ²ng thá»­ láº¡i.';
        } else if (error.name === 'TypeError') {
          errorMessage += 'TrÃ¬nh duyá»‡t khÃ´ng há»— trá»£ truy cáº­p camera/microphone.';
        } else {
          errorMessage += error.message;
        }
        
        alert(errorMessage);
        onCallEnded();
      }
    };

    initializeCall();

    return () => {
      // Cleanup local stream
      if (localStreamRef.current) {
        localStreamRef.current.getTracks().forEach(track => {
          track.stop();
          console.log('ğŸ›‘ Stopped track:', track.kind);
        });
        localStreamRef.current = null;
      }
      // Cleanup WebRTC connections
      webrtcService.cleanup();
    };
  // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [callId, groupId, currentUserId, participants, stompClient, onCallEnded, webrtcService]);

  // handleRemoteStream must be defined before handleSignal
  const handleRemoteStream = useCallback((userId: string, stream: MediaStream) => {
    console.log('ğŸ¥ ====================================');
    console.log('ğŸ¥ REMOTE STREAM RECEIVED');
    console.log('ğŸ¥ User ID:', userId);
    console.log('ğŸ¥ Stream ID:', stream.id);
    console.log('ğŸ¥ Stream active:', stream.active);
    console.log('ğŸ¥ Video tracks:', stream.getVideoTracks().length);
    console.log('ğŸ¥ Audio tracks:', stream.getAudioTracks().length);
    
    const participant = activeParticipants.find(p => p.userId === userId);
    if (!participant) {
      console.error(' âŒ Participant not found for userId:', userId);
      console.log('Available activeParticipants:', activeParticipants);
      return;
    }

    console.log('âœ… Participant found:', participant.userName);

    setRemoteStreams((prev) => {
      // Remove existing stream for this user if any
      const filtered = prev.filter((s) => s.userId !== userId);
      const newStreams = [
        ...filtered,
        {
          userId,
          userName: participant.userName,
          userAvatar: participant.userAvatar,
          stream,
        },
      ];
      console.log('ğŸ“Š Remote streams count:', newStreams.length);
      return newStreams;
    });

    // Update connection state
    setConnectionStates((prev) => {
      const newMap = new Map(prev);
      newMap.set(userId, webrtcService.getConnectionState(userId));
      return newMap;
    });
    
    console.log('ğŸ¥ ====================================');
  }, [activeParticipants, webrtcService]);

  const handleUserLeft = useCallback((userId: string) => {
    console.log('ğŸ‘‹ User left:', userId);
    webrtcService.removePeer(userId);
    setRemoteStreams((prev) => prev.filter((s) => s.userId !== userId));
    setConnectionStates((prev) => {
      const newMap = new Map(prev);
      newMap.delete(userId);
      return newMap;
    });
  }, [webrtcService]);

  // Define handleSignal with useCallback to prevent re-subscriptions
  const handleSignal = useCallback((signal: any) => {
    console.log('ğŸ“¨ ========================================');
    console.log('ğŸ“¨ SIGNAL RECEIVED:', signal.type);
    console.log('ğŸ“¨ From:', signal.fromUserId);
    console.log('ğŸ“¨ To:', signal.toUserId);
    console.log('ğŸ“¨ Current user:', currentUserId);
    
    switch (signal.type) {
      case 'PEER_OFFER':
        console.log('ğŸ“¨ Processing PEER_OFFER...');
        webrtcService.handleOffer(signal.fromUserId, signal.data, handleRemoteStream);
        break;
      case 'PEER_ANSWER':
        console.log('ğŸ“¨ Processing PEER_ANSWER...');
        webrtcService.handleAnswer(signal.fromUserId, signal.data);
        break;
      case 'ICE_CANDIDATE':
        console.log('ğŸ“¨ Processing ICE_CANDIDATE...');
        webrtcService.handleIceCandidate(signal.fromUserId, signal.data);
        break;
      case 'USER_JOINED':
        console.log('ğŸ‘¤ USER_JOINED - Creating offer to new user:', signal.fromUserId);
        if (signal.fromUserId !== currentUserId && signal.data) {
          // Add new participant to state
          const newParticipant: ParticipantInfo = {
            userId: signal.data.userId,
            userName: signal.data.userName,
            userAvatar: signal.data.userAvatar
          };
          console.log('â• Adding participant to state:', newParticipant);
          setActiveParticipants(prev => {
            // Check if participant already exists
            if (prev.some(p => p.userId === newParticipant.userId)) {
              console.log('âš ï¸ Participant already exists, skipping');
              return prev;
            }
            const updated = [...prev, newParticipant];
            console.log('âœ… Updated participants:', updated);
            return updated;
          });
          
          webrtcService.createOffer(signal.fromUserId, handleRemoteStream);
        } else {
          console.log('â­ï¸ Skipping - user is self');
        }
        break;
      case 'USER_LEFT':
        console.log('ğŸ‘‹ USER_LEFT:', signal.fromUserId);
        handleUserLeft(signal.fromUserId);
        break;
      case 'CALL_ENDED':
        console.log('ğŸ“ CALL_ENDED');
        onCallEnded();
        break;
      default:
        console.warn('âš ï¸ Unknown signal type:', signal.type);
    }
    console.log('ğŸ“¨ ========================================');
  }, [currentUserId, webrtcService, handleRemoteStream, handleUserLeft, onCallEnded]);

  // Subscribe to WebRTC signals - CRITICAL: Must be after handleSignal is defined!
  useEffect(() => {
    if (!stompClient || !stompClient.connected) {
      console.warn('âš ï¸ StompClient not connected, cannot subscribe to signals');
      return;
    }

    console.log('ğŸ”” Setting up WebRTC signal subscriptions...');
    
    // Subscribe to user-specific signals (PEER_OFFER, PEER_ANSWER, ICE_CANDIDATE)
    const userSignalSub = stompClient.subscribe(
      `/topic/group-video-signal/${currentUserId}`,
      (message) => {
        const signal = JSON.parse(message.body);
        console.log('ğŸ“¨ User-specific signal received:', signal.type);
        handleSignal(signal);
      }
    );
    console.log('âœ… Subscribed to user signals:', `/topic/group-video-signal/${currentUserId}`);

    // Subscribe to group-wide signals (USER_JOINED, USER_LEFT, CALL_ENDED)
    const groupSignalSub = stompClient.subscribe(
      `/topic/group-video-call/${groupId}`,
      (message) => {
        const signal = JSON.parse(message.body);
        console.log('ğŸ“¢ Group-wide signal received:', signal.type);
        
        // Only process USER_JOINED, USER_LEFT, CALL_ENDED
        // CALL_INITIATED is handled by Chat.tsx
        if (signal.type === 'USER_JOINED' || signal.type === 'USER_LEFT' || signal.type === 'CALL_ENDED') {
          handleSignal(signal);
        }
      }
    );
    console.log('âœ… Subscribed to group signals:', `/topic/group-video-call/${groupId}`);

    // Cleanup subscriptions on unmount
    return () => {
      console.log('ğŸ§¹ Cleaning up WebRTC signal subscriptions');
      userSignalSub?.unsubscribe();
      groupSignalSub?.unsubscribe();
    };
  }, [stompClient, currentUserId, groupId, handleSignal]);

  const handleToggleAudio = () => {
    if (localVideoRef.current && localVideoRef.current.srcObject) {
      const stream = localVideoRef.current.srcObject as MediaStream;
      stream.getAudioTracks().forEach((track) => {
        track.enabled = !track.enabled;
      });
      setIsAudioEnabled(!isAudioEnabled);
    }
  };

  const handleToggleVideo = () => {
    if (localVideoRef.current && localVideoRef.current.srcObject) {
      const stream = localVideoRef.current.srcObject as MediaStream;
      stream.getVideoTracks().forEach((track) => {
        track.enabled = !track.enabled;
      });
      setIsVideoEnabled(!isVideoEnabled);
    }
  };

  const handleLeaveCall = async () => {
    try {
      // Stop local stream first
      if (localStreamRef.current) {
        localStreamRef.current.getTracks().forEach(track => {
          track.stop();
          console.log('ğŸ›‘ Stopped track on leave:', track.kind);
        });
      }
      
      await leaveGroupCall(callId, currentUserId);
      onCallEnded();
    } catch (error) {
      console.error('Error leaving call:', error);
      onCallEnded();
    }
  };

  const handleEndCall = async () => {
    try {
      // Stop local stream first
      if (localStreamRef.current) {
        localStreamRef.current.getTracks().forEach(track => {
          track.stop();
          console.log('ğŸ›‘ Stopped track on end:', track.kind);
        });
      }
      
      await endGroupCall(callId);
      onCallEnded();
    } catch (error) {
      console.error('Error ending call:', error);
      onCallEnded();
    }
  };

  const isCaller = currentUserId === initiatorId;

  return (
    <div className="group-video-call-overlay">
      <div className="group-video-call-container">
        {/* Header */}
        <div className="call-header">
          <div className="call-info">
            <span className="group-name">ğŸ“¹ {groupName}</span>
            <span className="participant-count">
              ğŸ‘¥ {remoteStreams.length + 1} ngÆ°á»i
            </span>
          </div>
          <button className="minimize-btn" onClick={onCallEnded}>
            âˆ’
          </button>
        </div>

        {/* Video Grid */}
        <div className="video-grid">
          {/* Local Video */}
          <div className="video-container local">
            <video
              ref={localVideoRef}
              autoPlay
              playsInline
              muted
              className="video-element"
            />
            <div className="video-label">ğŸ‘¤ Báº¡n</div>
            {!isVideoEnabled && (
              <div className="video-off-overlay">
                <span>ğŸ“·</span>
              </div>
            )}
          </div>

          {/* Remote Videos */}
          {remoteStreams.map((remote) => (
            <RemoteVideoPlayer
              key={remote.userId}
              userId={remote.userId}
              userName={remote.userName}
              userAvatar={remote.userAvatar}
              stream={remote.stream}
              connectionState={connectionStates.get(remote.userId) || 'connecting'}
            />
          ))}
        </div>

        {/* Controls */}
        <div className="call-controls">
          <button
            className={`control-btn ${!isAudioEnabled ? 'off' : ''}`}
            onClick={handleToggleAudio}
            title={isAudioEnabled ? 'Táº¯t micro' : 'Báº­t micro'}
          >
            {isAudioEnabled ? 'ğŸ¤' : 'ğŸ”‡'}
          </button>

          <button
            className={`control-btn ${!isVideoEnabled ? 'off' : ''}`}
            onClick={handleToggleVideo}
            title={isVideoEnabled ? 'Táº¯t camera' : 'Báº­t camera'}
          >
            {isVideoEnabled ? 'ğŸ“¹' : 'ğŸ“µ'}
          </button>

          {/* Only initiator sees "End Call" button, others see "Leave" button */}
          {isCaller ? (
            <button
              className="control-btn end"
              onClick={handleEndCall}
              title="Káº¿t thÃºc cuá»™c gá»i cho táº¥t cáº£"
            >
              âŒ Káº¿t thÃºc
            </button>
          ) : (
            <button
              className="control-btn leave"
              onClick={handleLeaveCall}
              title="Rá»i khá»i cuá»™c gá»i"
            >
              ğŸšª Rá»i
            </button>
          )}
        </div>
      </div>
    </div>
  );
};

// Component for rendering remote video player
interface RemoteVideoPlayerProps {
  userId: string;
  userName: string;
  userAvatar: string;
  stream: MediaStream;
  connectionState: string;
}

const RemoteVideoPlayer: React.FC<RemoteVideoPlayerProps> = ({
  userId,
  userName,
  userAvatar,
  stream,
  connectionState
}) => {
  const videoRef = useRef<HTMLVideoElement>(null);

  useEffect(() => {
    console.log('ğŸ“º RemoteVideoPlayer useEffect for:', userName);
    console.log('ğŸ“º Video ref:', videoRef.current ? 'exists' : 'null');
    console.log('ğŸ“º Stream:', stream ? stream.id : 'null');
    
    if (videoRef.current && stream) {
      console.log('âœ… Setting srcObject for:', userName);
      console.log('ğŸ“º Stream active:', stream.active);
      console.log('ğŸ“º Video tracks:', stream.getVideoTracks().length);
      console.log('ğŸ“º Audio tracks:', stream.getAudioTracks().length);
      
      videoRef.current.srcObject = stream;
      
      // Add event listeners to debug
      videoRef.current.onloadedmetadata = () => {
        console.log('âœ… Video metadata loaded for:', userName);
      };
      
      videoRef.current.onplay = () => {
        console.log('â–¶ï¸ Video playing for:', userName);
      };
      
      videoRef.current.onerror = (e) => {
        console.error('âŒ Video error for:', userName, e);
      };
    } else {
      console.warn('âš ï¸ Cannot set srcObject - ref or stream missing');
    }
  }, [stream, userName]);

  return (
    <div className="video-container remote">
      <video
        ref={videoRef}
        autoPlay
        playsInline
        className="video-element"
      />
      <div className="user-avatar">
        <img src={userAvatar} alt={userName} />
      </div>
      <div className="video-label">
        ğŸ‘¤ {userName}
        {connectionState !== 'connected' && (
          <span className="connection-status"> ({connectionState})</span>
        )}
      </div>
    </div>
  );
};

export default GroupVideoCallInterface;
